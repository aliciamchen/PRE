var params = {
    alpha: 1,
    actions: ['A_A', 'A_B', 'B_B', 'B_A']
}

var round = function (num, precision) {
    Number.parseFloat(num.toFixed(precision));
};

var Beta_disc = cache(function (hypers) {
    return Infer({ method: 'enumerate' }, function () {
        var n = uniformDraw(_.range(0, 1, 0.01));
        var bta = Beta({
            a: hypers.a == 0 ? 1 : hypers.a,
            b: hypers.b == 0 ? 1 : hypers.b
        });
        factor(bta.score(n));
        return round(n, 2);
    })
});

/*
'A' corresponds to Person A's preferred action
'B' corresponds to Person B's preferred action
So 'B_A' corresponds to the payoffs
of A doing B's preferred action and B doing A's preferred action
*/

var scenario_payoffs = {
    'restaurant': {
        'A_A': {'A': 5, 'B': 4},
        'A_B': {'A': 1, 'B': 1}, // each person gets some reward for doing their preferred action (but not as much as if they did it together)
        'B_B': {'A': 4, 'B': 5},
        'B_A': {'A': 0, 'B': 0}
    }
}

var actor = function(payoffs, weights) {
    var U_A = function(action) {
        var R_A = payoffs[action]['A']
        var R_B = payoffs[action]['B']
        return R_A + weights['w_B'] * R_B
    }

    var U_B = function(action) {
        var R_A = payoffs[action]['A']
        var R_B = payoffs[action]['B']
        return R_B + weights['w_A'] * R_A
    }

    // TODO: compute all the utilities of all the possible sets of action, flip to pick that action compared to the other actions
    // TODO: should i have an exit?

}

var observer = function(payoffs, action_sequence) {
    return Infer({method: 'enumerate'}, function () {

        // start with uniform priors on weights
        var weights = {
            'w_A': sample(Beta_disc({a: 1, b: 1})), // how much B weighs A's utility
            'w_B': sample(Beta_disc({a: 1, b: 1})) // how much A weighs B's utility
        }

        var U_A = function(action) {
            var R_A = payoffs[action]['A']
            var R_B = payoffs[action]['B']
            return R_A + weights['w_B'] * R_B
        }

        var U_B = function(action) {
            var R_A = payoffs[action]['A']
            var R_B = payoffs[action]['B']
            return R_B + weights['w_A'] * R_A
        }

        var obsFn = function(datum){
            // assumption that both agents want to maximize their utility over action sequence
            factor(params.alpha * U_A(datum))
            factor(params.alpha * U_B(datum))
        }

        mapData({data: action_sequence}, obsFn)

        return weights
    })
}

// viz(observer(scenario_payoffs['restaurant'], ['A_A', 'A_A', 'A_A', 'A_A', 'A_A', 'A_A']))
// viz(observer(scenario_payoffs['restaurant'], ['B_B', 'B_B', 'B_B', 'B_B', 'B_B', 'B_B']))
